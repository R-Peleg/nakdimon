{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import dataset\n",
    "assert tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 64, 110)      4840        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 64, 220)      582560      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 64, 220)      776160      bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 220)      0           bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 64, 16)       3536        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 64, 3)        663         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 64, 4)        884         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "N (Softmax)                     (None, 64, 16)       0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "D (Softmax)                     (None, 64, 3)        0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "S (Softmax)                     (None, 64, 4)        0           dense_20[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,368,643\n",
      "Trainable params: 1,368,643\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAXLEN = 64\n",
    "\n",
    "LETTERS_SIZE = len(dataset.letters_table)\n",
    "NIQQUD_SIZE = len(dataset.niqqud_table)\n",
    "DAGESH_SIZE = len(dataset.dagesh_table)\n",
    "SIN_SIZE = len(dataset.sin_table)\n",
    "\n",
    "def build_model(EMBED_DIM=110, UNITS=220):\n",
    "\n",
    "    layer = input_text = tf.keras.Input(batch_shape=(None, MAXLEN), batch_size=BATCH_SIZE)\n",
    "    \n",
    "    layer = layers.Embedding(LETTERS_SIZE, EMBED_DIM, mask_zero=True)(layer)\n",
    "    layer = layers.Bidirectional(layers.LSTM(UNITS, return_sequences=True, dropout=0.1), merge_mode='sum')(layer)\n",
    "    layer = layers.add([layer,\n",
    "                         layers.Bidirectional(layers.LSTM(UNITS, return_sequences=True, dropout=0.1), merge_mode='sum')(layer)])\n",
    "\n",
    "    outputs = [\n",
    "        layers.Softmax(name='N')(layers.Dense(NIQQUD_SIZE)(layer)),\n",
    "        layers.Softmax(name='D')(layers.Dense(DAGESH_SIZE)(layer)),\n",
    "        layers.Softmax(name='S')(layers.Dense(SIN_SIZE)(layer))\n",
    "    ]\n",
    "    model = tf.keras.Model(inputs=[input_text], outputs=outputs)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # tf.keras.utils.plot_model(model, to_file='model.png')\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "def fit(data, learning_rates):\n",
    "    x  = data.normalized_texts\n",
    "    vx = data.normalized_validation\n",
    "    y  = {'N': data.niqqud_texts,      'D': data.dagesh_texts,      'S': data.sin_texts,      'C': data.normalized_texts     }\n",
    "    vy = {'N': data.niqqud_validation, 'D': data.dagesh_validation, 'S': data.sin_validation, 'C': data.normalized_validation}\n",
    "    return model.fit(x, y, validation_data=(vx, vy), batch_size=BATCH_SIZE, epochs=len(learning_rates),\n",
    "          callbacks=[\n",
    "              tf.keras.callbacks.LearningRateScheduler(lambda epoch, lr: learning_rates[epoch], verbose=0),\n",
    "          ]\n",
    "    )\n",
    "\n",
    "model.summary()\n",
    "model.save_weights('./checkpoints/uninit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(source, maxlen=MAXLEN):\n",
    "    filenames = [os.path.join('texts', f) for f in source]\n",
    "    return dataset.load_file(filenames, BATCH_SIZE, 0.1, maxlen=maxlen, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rabanit = load_data(['birkat_hamazon.txt', 'kuzari.txt', 'hakdama_leorot.txt', 'hartzaat_harav.txt', 'orhot_hayim.txt', 'rambam_mamre.txt', 'short_table.txt', 'tomer_dvora.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_modern = load_data(['elef_layla.txt', 'bialik', 'shaul_tchernichovsky', 'breslev.txt', 'itzhak_berkman', 'zevi_scharfstein', 'pesah_kaplan', 'abraham_regelson',\n",
    "                             'elisha_porat', 'uriel_ofek', 'yisrael_dushman', 'zvi_zviri', 'atar_hashabat.txt', 'ali_baba.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modern = load_data(['forums', 'newspapers', 'wiki', 'blogs', 'adamtsair.txt', 'katarsis.txt'])  # , 'imagination.txt', 'sipurim.txt', 'ricky.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76377 samples, validate on 8487 samples\n",
      "Epoch 1/2\n",
      "76377/76377 [==============================] - 91s 1ms/sample - loss: 0.3397 - N_loss: 0.2651 - D_loss: 0.0657 - S_loss: 0.0089 - N_accuracy: 0.9073 - D_accuracy: 0.9745 - S_accuracy: 0.9975 - val_loss: 0.1583 - val_N_loss: 0.1195 - val_D_loss: 0.0356 - val_S_loss: 0.0034 - val_N_accuracy: 0.9592 - val_D_accuracy: 0.9870 - val_S_accuracy: 0.99932877 - D_loss: 0.0702 - S_loss: 0.0098 - N_accuracy: 0.8992 - D_accuracy: 0.9726 - S_accuracy - ETA: 12s - loss: 0.3671 - N_loss: 0.2872 - D_loss: 0.0701 - S_loss - ETA: 9s - loss: 0.3604 - N_loss: 0.2818 - D_loss: 0.0691 - S_loss: 0.0096 - N_accuracy: 0.9013 - D_accuracy: 0 - ETA: 7s - loss: 0.3560 - N_loss: 0.2783 - D_loss: 0.0683 - S_loss: 0.0094 - N_accuracy: 0.902 - ETA: 4s - loss: 0.3494 - N_loss: 0.2730 - D_loss: 0.0673 - S_loss: 0.0092 - N_acc - ETA: 0s - loss: 0.3413 - N_loss: 0.2664 - D_loss: 0.0660 - S_loss: 0.0089 - N_accuracy: 0.9068 - D_accuracy: 0.9744 - S_accu\n",
      "Epoch 2/2\n",
      "76377/76377 [==============================] - 82s 1ms/sample - loss: 0.1382 - N_loss: 0.1040 - D_loss: 0.0316 - S_loss: 0.0027 - N_accuracy: 0.9646 - D_accuracy: 0.9885 - S_accuracy: 0.9994 - val_loss: 0.1224 - val_N_loss: 0.0913 - val_D_loss: 0.0286 - val_S_loss: 0.0028 - val_N_accuracy: 0.9693 - val_D_accuracy: 0.9899 - val_S_accuracy: 0.9994N_loss: 0.1193 - D_loss: 0.0369 - S_loss: 0.0029 - N_accuracy: 0.9597 - D_accuracy: 0.9868 - S_acc - ETA: 1:14 - loss: 0.1566 - N_loss: 0.1177 - D_loss: 0.0362 - S_loss: 0.0027 - N_accuracy: 0.9601 - D_accuracy: 0.9870 -  - ETA: 1:13 - loss: 0.1543 - N_loss: 0.1158 - D_loss: 0.0358 - S_loss: 0.0028 - N_accuracy: 0.9605 - D_accuracy: 0.9871 - S_accuracy: 0.99 - ETA: 1:13 - loss: 0.1544 - N_loss: 0.1158 - D_loss: 0.0359 - S_loss: 0.0028 - N_accuracy: 0.9605 - D_accuracy: 0.9871 -  - ETA: 1:12 - loss: 0.1537 - N_loss: 0.1153 - D_loss: 0.0355 - S_loss: 0.0028 - N_accuracy: 0.9604 - D_acc - ETA: 1:10 - loss: 0.1514 - N_loss: 0.1139 - D_loss: 0.0347 - S_loss: 0.0028 - N_accuracy: 0.9608 - D_accura - ETA: 1:08 - loss: 0.1492 - N_loss: 0.1123 - D_loss: 0.0341  - ETA: 1:02 - loss: 0.1469 - N_loss: 0.1107 - D_loss: 0.0334 - S_loss: 0.0027 - N_accuracy: 0.9621 - D_accu - ETA: 1:00 - loss: 0.1463 - N_loss: 0.1101 - D_loss: 0.0334 - S_loss: 0.0028 - N_accuracy: 0.9624 - D_accuracy: 0.9879 - S_accura - ETA: 59s - loss: 0.1458 - N_loss: 0.1097 - D_loss: 0.0333 - S_loss: 0.0028 - N_accuracy:  - ETA: 53s - loss: 0.1447 - N_loss: 0.1090 - D_loss: 0.0329 - S_loss: 0.0028 - N_ac - ETA: 51s - loss: 0.1445 - N_loss: 0.1088 - D_loss: 0.0329 - S_los - ETA: 49s - loss: 0.1440 - N_loss: 0.1084 - D_loss: 0.0328 - S_los - ETA: 47s - loss: 0.1432 - N_loss: 0.1078 - D_loss: 0.0327 - - ETA: 44s - loss: 0.1427 - N_loss: 0.1074 - D_loss: 0.0326 - S_loss: 0.0028 - N_accuracy: 0.9633 - D_acc - ETA: 43s - loss: 0.1425 - N_loss: - ETA: 35s - loss: 0.1412 - N_loss: 0.1063 - D_loss: 0.0323 - S - ETA: 33s - loss: 0.1411 - N_loss: 0.1061 - D_loss: 0.0322 - S_loss: 0.0027 - N_accuracy: 0.9638 - D_accuracy: 0.9882 - S_accu - ETA: 32s - loss: 0.1410 - N_loss: 0.1061 - D_loss: 0.0322 - S_loss: 0.0027 - N_accuracy: 0.9638 - D_accuracy: 0.9883 - S_accura - ETA: 32s - lo - ETA: 28s - loss: 0.1405 - N_loss: 0.1056 - D_loss: 0.0322 - S_loss: 0.0027 - N_accuracy: 0.9639 - D_accuracy: 0.9883 - S_accu - ETA: 28s - loss: 0.1406 - N_loss: 0.1057 - D_loss: 0.0322 - S_loss: 0.0027 - N_accuracy - ETA: 21s - loss: 0.1400 - N - ETA: 8s - loss: 0.1388 - N_loss: 0.1044 - D_loss: 0.0317 - ETA: 3s - loss: 0.1385 - N_loss: 0.1041 - D_loss: 0.0316 - S_loss: 0.0027 - N_accuracy: 0.9645 - D_accuracy: 0.98 - ETA: 1s - loss: 0.1384 - N_loss: 0.1041 - D_loss: 0.0316 - S_loss: 0.0027 - N_accuracy: 0.9645 - D_accuracy\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('./checkpoints/uninit')\n",
    "history = fit(data_rabanit, [3e-3, 3e-4])\n",
    "model.save_weights('./checkpoints/rabanit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84096 samples, validate on 9344 samples\n",
      "Epoch 1/2\n",
      "84096/84096 [==============================] - 89s 1ms/sample - loss: 0.2806 - N_loss: 0.2123 - D_loss: 0.0618 - S_loss: 0.0064 - N_accuracy: 0.9277 - D_accuracy: 0.9751 - S_accuracy: 0.9982 - val_loss: 0.2207 - val_N_loss: 0.1633 - val_D_loss: 0.0520 - val_S_loss: 0.0053 - val_N_accuracy: 0.9454 - val_D_accuracy: 0.9791 - val_S_accuracy: 0.9986 - S_loss: 0.0081 - N_accuracy: 0.8993 - D_accuracy: 0.9686 - S_accu - ETA: 1: - ETA: 1:22 - loss: 0.3490 - N_loss: 0.2682 - D_loss: 0.0730 - S_loss: 0.0078 - N_accuracy: 0.9087 - D_accuracy: - ETA: 1:18 - loss: 0.3441 - N_loss: 0.2643 - D_loss: 0.0722 - S_loss: 0.0076 - N_accuracy: 0.9099 - D_accuracy - ETA: 1:14 - loss: 0.3398 - N_loss: 0.2606 - D_loss: 0.0716 - S_loss:  - ETA: 1:07 - loss: 0.3307 - N_loss: 0.2531 - D_loss: 0.0702 - S_loss: 0.0074  - ETA: 1:01 - loss: 0.3245 - N_loss: 0.2479 - D_loss: 0.0693 - S_loss: 0.0073 - N_accuracy: 0.9 - ETA: 7s - loss: 0.2841 - N_loss: 0.2152 - D_loss: 0.0624 - S_loss: 0.0065 - - ETA: 3s - loss: 0.2824 - N_loss: 0.2138 - D_loss: 0.0621 - S_loss: 0.0065 - N_accuracy: 0.92 - ETA: 1s - loss: 0.2811 - N_loss: 0.2127 - D_loss: 0.0619 - S_loss: 0.0064 - N_accuracy: 0.9275 - D_accuracy: 0.9751 -\n",
      "Epoch 2/2\n",
      "84096/84096 [==============================] - 83s 990us/sample - loss: 0.2004 - N_loss: 0.1476 - D_loss: 0.0480 - S_loss: 0.0048 - N_accuracy: 0.9500 - D_accuracy: 0.9807 - S_accuracy: 0.9987 - val_loss: 0.1880 - val_N_loss: 0.1376 - val_D_loss: 0.0459 - val_S_loss: 0.0045 - val_N_accuracy: 0.9546 - val_D_accuracy: 0.9819 - val_S_accuracy: 0.998858 - N_a - ETA: 1:12 - loss: 0.2152 - N_loss: 0.1594 - D_loss: 0.0505 - S_loss: 0.0054 - N_accuracy: 0.9457 - D_accuracy: 0.9798 - S_accuracy: 0.998 - ETA: 1:12 - loss: 0.2153 - N_loss: 0.1594 - D_loss: 0.0504  - ETA: 1:07 - loss: 0.2134 - N_loss: 0.1582 - ETA: 1:01 - loss: 0.2108 - N_loss: 0.1560 - D_loss: 0.0498 - S_loss: 0.0051 - N_accuracy: 0.9472 - D_accuracy: 0.9799 - S_accur - ETA: 1:00 - loss: 0.2105 - N_loss: 0.1557 - D_loss: 0.0497 - S_loss: 0.00 - ETA: 58s - loss: 0.2094 - N_loss: 0.1549 - D_loss: 0.0495 - S_loss: 0.0050 - N_accuracy: 0.9476 - D_accuracy: - ETA: 57s - loss: 0.2093 - N_loss: 0.1547 - D_loss: 0.0495 - S_loss: 0.0051 - N_accuracy: 0.9476 - D_accuracy: 0.9801  - ETA: 56s - loss: 0.2089 - N_loss: 0.1545 - D_loss: 0.0493 - S_loss: 0.0051 - N_accuracy: 0. - ETA: 55s - loss: 0.2087 - N_loss: 0.1542 - D_loss: 0.0493 - S_loss: 0.0051 - N_accuracy: 0. - ETA: 50s - loss: 0.2076 - N_loss: 0.1534 - D_loss: 0. - ETA: 47s - loss: 0.2072 - N_loss: 0.1530 - D_loss: 0.0491 - S_loss: 0.0050 - N_accuracy: 0.9482 - D_accuracy: 0.9802  - ETA: 47s - loss: 0.2071 - N_loss: 0.1529 - D_loss: 0.0491 - S_loss: 0.0050 - N_accuracy: 0.9482 - D_accuracy: 0.9802 - S_ac - ETA: 46s - loss: 0.2068 - N_loss: 0.1528 - D_loss: 0.0491 - - ETA: 44s - loss: 0.2065 - N_loss: 0.1525 - D_loss: 0.0491 - S_loss: 0.0049 - N_accuracy: 0.9484 - D_accuracy: 0.9802 - S_accuracy: 0.99 - ETA: 44s - loss: 0.2066 - N_l - ETA: 40s - loss: 0.2059 - N_loss: 0 - ETA: 37 - - ETA: 25s - loss: 0.2031 - N_loss: 0.1497 - D_loss: 0.0484 - S_loss: 0.0049  - ETA: 23s - loss: 0.2027 - N_loss: 0.1494 - D_loss: 0.0484 - S_loss: 0.0049 - N_accuracy: 0.9494 - D_accuracy: 0.9805 - S_ac - ETA: 23s - loss: 0.2026 - N_loss: 0.1493 - D_loss: 0.0484 - S_loss: 0.0049 - N_accuracy: 0.9494 - D - ETA: 21s - loss: 0.2025 - N_loss: 0.1493 - D_loss: 0.0484 - S_loss: 0.0049 - N_accuracy: 0.9494 - D_accuracy: 0.9806  - ETA: 21s - loss: 0.2024 - N_loss: 0.1492 - D_loss: 0.0483 - S_loss: 0.0049 - N_accuracy:  - ETA: 19s - loss: 0.2022 - N_loss: 0.1491 - D_loss: 0.0483 - S_loss: 0.0049 - N_accu - ETA: 18s - loss: 0.2020 - N_loss: 0.1488 - D_loss: 0.0483 - S_los - ETA: 11s - loss: 0.2015 - N_loss: 0.1484 - D_loss: 0.0482 - S_loss: 0.0049 - N_accuracy: 0.9497 - D_accuracy: 0.9806 - S_accuracy: 0.99 - ETA: 11s - loss: 0.2015 - N_loss: 0.1484 - D_loss: 0.0482 - S_loss: 0.0049 - N_accuracy - ETA: 10s - loss: 0.2013 - N_loss: 0.1483 - D_loss: 0.0482 - S_loss: 0.0048 - N_accuracy: 0.94 - ETA: 8s - loss: 0.2012 - N_loss: 0.1482 - D_loss: 0.0482 - S_loss: 0.0048 - N_accuracy: 0.9498 - D_accur - ETA: 6s - loss: 0.2009 - N_loss: 0.1480 - D_loss: 0.0481 - S_loss: 0.0048 - N_accuracy: 0.9499 - D_accuracy: 0.9807 - S_accuracy: 0.99 - ETA: 5s - loss: 0.2008 - N_loss: 0.14\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('./checkpoints/rabanit')\n",
    "history = fit(data_pre_modern, [3e-3, 3e-4])\n",
    "model.save_weights('./checkpoints/pre_modern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11692 samples, validate on 1300 samples\n",
      "Epoch 1/2\n",
      "11692/11692 [==============================] - 13s 1ms/sample - loss: 0.2441 - N_loss: 0.1825 - D_loss: 0.0563 - S_loss: 0.0053 - N_accuracy: 0.9419 - D_accuracy: 0.9783 - S_accuracy: 0.9988 - val_loss: 0.1968 - val_N_loss: 0.1476 - val_D_loss: 0.0436 - val_S_loss: 0.0050 - val_N_accuracy: 0.9560 - val_D_accuracy: 0.9831 - val_S_accuracy: 0.9990\n",
      "Epoch 2/2\n",
      "11692/11692 [==============================] - 13s 1ms/sample - loss: 0.1583 - N_loss: 0.1163 - D_loss: 0.0384 - S_loss: 0.0035 - N_accuracy: 0.9642 - D_accuracy: 0.9854 - S_accuracy: 0.9992 - val_loss: 0.1753 - val_N_loss: 0.1315 - val_D_loss: 0.0389 - val_S_loss: 0.0044 - val_N_accuracy: 0.9612 - val_D_accuracy: 0.9850 - val_S_accuracy: 0.9990_accuracy:  - ETA: 5s - loss: 0.1612 - N_loss: 0.1186 - D_loss: 0.0390 - S_loss: 0.0035 - N_accuracy: 0.963 - ETA: 2s - loss: 0.1588 - N_loss: 0.1165 - D_loss: 0.0387 - S_loss: 0.0036 - N_accuracy: 0.9640 - D_ac - ETA: 0s - loss: 0.1581 - N_loss: 0.1161 - D_loss: 0.0384 - S_loss: 0.0035 - N_accuracy: 0.9642 - D_accuracy: 0.9854 - S_accuracy:\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('./checkpoints/pre_modern')\n",
    "history = fit(data_modern, [3e-3, 3e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "for n, v in enumerate(['accuracy', 'loss'], 0):\n",
    "    for n1, t in enumerate(['D', 'N'], 0):\n",
    "        p = ax[n][n1]\n",
    "        p.plot(history.history[t + '_' + v][0:])\n",
    "        p.plot(history.history['val_' + t + '_' +  v][0:])\n",
    "        p.legend([t + '_Train', t + '_Test'], loc='center right')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "tfjs.converters.save_keras_model(model, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "מצוי:  לְכִיוּוּן הַמַּתְאִים. תְּנוּ לָהֶם עוֹד חוֹפֶשׁ לִפְנֵי הַתִּיקּוּן וְהֵם יִשָׂאֲפוּ לְסַבְסֵב אֶת\n",
      "רצוי:  לַכִּיוּוּן הַמַּתְאִים. תְּנוּ לָהֶם עוֹד חוֹפֶשׁ לִפְנֵי הַתִּיקּוּן וְהֵם יִשְׁאֲפוּ לְסַבְסֵב אֶת\n",
      "\n",
      "מצוי:  לַפִיהָ הַגֶּנֵטִיקָה שֶׁיָּרַשְׁנוּ הִיא הַגּוֹרֵם הַמֶּרְכָּזִי שֶׁקּוֹבֵעַ אֶת עָתִידֵנוּ הַבְּרִיאוּתִי,\n",
      "רצוי:  לְפִיהָ הַגֵּנֵטִיקָה שֶׁיָּרַשְׁנוּ הִיא הַגּוֹרֵם הַמֶּרְכָּזִי שֶׁקּוֹבֵעַ אֶת עֲתִידֵנוּ הַבְּרִיאוּתִי,\n",
      "\n",
      "מצוי:  זָקוּק לָהּ בְּמַצַּב הַחֵירוּם הַנּוֹכְחִי\". נַזְכִּיר כִּי בְּיוֹם שְׁנֵי הָאַחֲרוֹן הוּפְסַק\n",
      "רצוי:  זָקוּק לָהּ בְּמַצַּב הַחֵירוּם הַנּוֹכְחִי\". נַזְכִּיר כִּי בַּיּוֹם שֵׁנִי הָאַחֲרוֹן הוּפְסַק\n",
      "\n",
      "מצוי:  טִיפָּה נִלְחַצְתִּי: זְכוּת גְּדוֹלָה וּסְגִירַת מַעְגָּל. הִסְתַּכַּלְתִּי עַל הָאוּלָם. יָשְׁבָה שָׁם\n",
      "רצוי:  טִיפָּה נִלְחַצְתִּי: זְכוּת גְּדוֹלָה וּסְגִירַת מַעְגָּל. הִסְתַּכַּלְתִּי עַל הָאוּלָם. יָשְׁבָה שָׁם\n",
      "\n",
      "מצוי:  עִם שְׁתֵּי כּוֹסוֹת תָּה. \"אֲנִי מִצְטַעֵר שֶׁזֶּה כָּכָה, פָּשׁוּט הַמִּטְבָּח שֶׁלָּנוּ בַּחוּץ\".\n",
      "רצוי:  עִם שְׁתֵּי כּוֹסוֹת תֵּה. \"אֲנִי מִצְטַעֵר שֶׁזֶּה כָּכָה, פָּשׁוּט הַמִּטְבָּח שֶׁלָּנוּ בַּחוּץ\".\n",
      "\n",
      "מצוי:  הָיְיתָה טָעוּת שֶׁלֹּא הָיְיתָה בָּהּ כַּוּונָה רָעָה לִפְגּוֹעַ וְהָיְיתָה גַּם הִתְנַצְּלוּת. אֲנִי\n",
      "רצוי:  הָיְיתָה טָעוּת שֶׁלֹּא הָיְיתָה בָּהּ כַּוּוֹנָה רָעָה לִפְגּוֹעַ וְהָיְיתָה גַּם הִתְנַצְּלוּת. אֲנִי\n",
      "\n",
      "מצוי:  הַדִּיּוּן בְּוַּועֲדָה בְּשִׁידּוּר חַי. תִּבְדְּקוּ אֶת הָעוּבְדּוֹת. מְדִבְּרֵי הַמַּפְכָּ\"ל בַּכְּנֶסֶת\n",
      "רצוי:  הַדִּיּוּן בַּוַּועֲדָה בְּשִׁידּוּר חַי. תִּבְדְּקוּ אֶת הָעוּבְדּוֹת. מְדַבְּרֵי הַמַּפְכָּ\"ל בַּכְּנֶסֶת\n",
      "\n",
      "מצוי:  לְשִׁיפּוּר מוּכָנוֹת הָעוֹרֶף, אֲפִילּוּ אִם הַמֶּמְשָׁלָה הִיא מֶמְשֶׁלֶת מֵעֵבֶר שֶׁסַּמְכוּיוֹתֶיהָ\n",
      "רצוי:  לְשִׁיפּוּר מוּכָנוֹת הָעוֹרֶף, אֲפִילּוּ אִם הַמֶּמְשָׁלָה הִיא מֶמְשֶׁלֶת מַעֲבָר שֶׁסַּמְכוּיוֹתֶיהָ\n",
      "\n",
      "מצוי:  לְסִיּוּם, שְׁנֵי סִיפּוּרִים חִיּוּבִיִּים: מִיטַל (55) מָצְאָה אֶת הָאַהֲבָה שֶׁלָּהּ בְּטִינְדֶּר,\n",
      "רצוי:  לְסִיּוּם, שְׁנֵי סִיפּוּרִים חִיּוּבִיִּים: מֵיטַל (55) מָצְאָה אֶת הָאַהֲבָה שֶׁלָּהּ בְּטִינְדֶּר,\n",
      "\n",
      "מצוי:  לְאוּטִין, אַלְמָנָה שֶׁל מַרְגָּרִיטָה שֶׁנִּרְצְחָה בְּבַת יָם, אָמַר בְּדִּיּוּן כִּי \"לִי זֶה קָרָה\n",
      "רצוי:  לָאוֹטֵין, אַלְמָנָה שֶׁל מַרְגָּרִיטָה שֶׁנִּרְצְחָה בְּבַת יָם, אָמַר בַּדִּיּוּן כִּי \"לִי זֶה קָרָה\n",
      "\n",
      "מצוי:  הָיְיתָה עַל זֶה שִׂיחָה אֲפִילּוּ. בְּטִיק טוֹק, לְעוּמַּת זֹאת, יֵשׁ לָהּ יוֹתֵר מִמֵּאָה\n",
      "רצוי:  הָיְיתָה עַל זֶה שִׂיחָה אֲפִילּוּ. בְּטִיק טוֹק, לְעוּמַּת זֹאת, יֵשׁ לָהּ יוֹתֵר מִמֵּאָה\n",
      "\n",
      "מצוי:  לַהַזְמָנָה שֶׁלָּכֶם לַסֶּרֶט אוֹ לִיוּוֹה אֵיזוֹ סִדְרָה אֲהוּבָה - מִיָּד תִּיזְכְּרוּ בְּכָל מָה\n",
      "רצוי:  לַהַזְמָנָה שֶׁלָּכֶם לְסֶרֶט אוֹ לִיוּוֹה אֵיזוֹ סִדְרָה אֲהוּבָה - מִיָּד תִּיזְכְּרוּ בְּכָל מָה\n",
      "\n",
      "מצוי:  מִלְחָמָה בֵּין אַרְהָ\"ב לְאִירָאן. מֵאֲחוֹרֵי הַהַסְלָמָה שֶׁל הַמִּילִיצְיוֹת נֶגֶד הַנּוֹכְחוּת\n",
      "רצוי:  מִלְחָמָה בֵּין אַרְהָ\"ב לְאִירָאן. מֵאֲחוֹרֵי הַהַסְלָמָה שֶׁל הַמִּילִיצְיוֹת נֶגֶד הַנּוֹכְחוּת\n",
      "\n",
      "מצוי:  וּלְבַקֵּשׁ מֵהֶם לַעֲטוֹת מַסֵּכָה, מֵאַחַר שֶׁבִּידֵי הַשּׁוֹטְרִים אֵין כֵּלִים לֶאֱכוֹף אֶת\n",
      "רצוי:  וּלְבַקֵּשׁ מֵהֶם לַעֲטוֹת מַסֵּכָה, מֵאַחַר שֶׁבִּידֵי הַשּׁוֹטְרִים אֵין כֵּלִים לֶאֱכוֹף אֶת\n",
      "\n",
      "מצוי:  זֶה מֵאסְט אֶצְלִי, אֲבָל אֲנִי יוֹתֵר אוֹהֵב בַּסָּלוֹן\". דּוּבִי: \"לֹא פֹּה וְלֹא שָׁם.\n",
      "רצוי:  זֶה מַאסְט אֶצְלִי, אֲבָל אֲנִי יוֹתֵר אוֹהֵב בַּסָּלוֹן\". דּוּבִּי: \"לֹא פֹּה וְלֹא שָׁם.\n",
      "\n",
      "מצוי:  הֲכִי הֲכִי טְהוֹרָה שֶׁאֲנִי מַכִּירָה. זֶה לֹא פֵּייר\". מִי לָקַח יוֹתֵר קָשֶׁה אֶת הַפָּרָשָׁה\n",
      "רצוי:  הֲכִי הֲכִי טְהוֹרָה שֶׁאֲנִי מַכִּירָה. זֶה לֹא פֵייר\". מִי לָקַח יוֹתֵר קָשֶׁה אֶת הַפָּרָשָׁה\n",
      "\n",
      "מצוי:  זֶה זְמַן אֵיכוּת אֶחָד עִם הַשֵּׁנִי, מְדַבְּרִים בְּסוֹף יוֹם, שִׂיחַת סִיכּוּם כַּזֹאת, זֶה\n",
      "רצוי:  זה זמן איכות אחד עם השני, מדברים בסוף יום, שיחת סיכום כזאת, זה\n",
      "\n",
      "מצוי:  קְצָת חַיּוֹת בַּבַּיִת וְדֵנִיס זֶרַם עַל זֶה\", מְסַפֶּרֶת הֲדַר. \"בְּסוֹפוֹ שֶׁל דָּבָר הוּא דַּי\n",
      "רצוי:  קְצָת חַיּוֹת בַּבַּיִת וְדֶנִיס זָרַם עַל זֶה\", מְסַפֶּרֶת הֲדַר. \"בְּסוֹפוֹ שֶׁל דָּבָר הוּא דֵּי\n",
      "\n",
      "מצוי:  שְׁלוֹשָׁה יְלָדִים - טוֹהֵר עֲמִירָה, תָּאִיר אֶפְּשְׁטֵיין וְעוֹמְרֵי עֲמִירָה, וּנְכְדִים.\n",
      "רצוי:  שְׁלוֹשָׁה יְלָדִים - טוֹהַר עֲמִירָה, תָּאִיר אֶפְּשְׁטָיין וְעוֹמְרִי עֲמִירָה, וּנְכָדִים.\n",
      "\n",
      "מצוי:  הַהַפְרָדָה הַזּוֹ, שֶׁעֲדַיִין קַיֶּימֶת לְמַרְבֵּה הַצַּעַר, מְבִיאָה לְכָךְ שֶׁשְּׁנֵי הַגּוֹרְמִים\n",
      "רצוי:  הַהַפְרָדָה הַזּוֹ, שֶׁעֲדַיִין קַיֶּימֶת לְמַרְבֵּה הַצַּעַר, מְבִיאָה לְכָךְ שֶׁשְּׁנֵי הַגּוֹרְמִים\n",
      "\n",
      "מצוי:  סוֹד גָּלוּי - זֶה לֹא כָּל כָּךְ קָשֶׁה כְּמוֹ שֶׁזֶּה נִרְאֶה. הַחְלָקָה לְרוֹחֵב, הִתְיַישְּׁרוּת\n",
      "רצוי:  סוֹד גָּלוּי - זֶה לֹא כָּל כָּךְ קָשֶׁה כְּמוֹ שֶׁזֶּה נִרְאֶה. הַחֶלְקָה לְרוֹחַב, הִתְיַישְּׁרוּת\n",
      "\n",
      "מצוי:  לִי לִישׁוֹן אֵיתָּן בַּלַּיְלָה. אֲבָל בָּאָרֶץ, כַּמָּה אֲנָשִׁים יְכוֹלִים לִחְיוֹת מֵהַמִּקְצוֹעַ\n",
      "רצוי:  לִי לִישׁוֹן אֵיתָן בַּלַּיְלָה. אֲבָל בָּאָרֶץ, כַּמָּה אֲנָשִׁים יְכוֹלִים לִחְיוֹת מֵהַמִּקְצוֹעַ\n",
      "\n",
      "מצוי:  אוֹתִיּוֹת שְׁמָם אוֹ סְכוּם סִפְרוֹת תַּאֲרִיךְ לִידָתָם - מִסְתַּכֵּם בְּ-5. הָאֵנֶרְגִּיּוֹת שֶׁל\n",
      "רצוי:  אוֹתִיּוֹת שְׁמָם אוֹ סְכוּם סְפָרוֹת תַּאֲרִיךְ לֵידָתָם - מִסְתַּכֵּם בְּ-5. הָאֵנֶרְגִּיּוֹת שֶׁל\n",
      "\n",
      "מצוי:  גּוּפָנִי: הֵן מַחַקוֹת אֶת פְּעִילוּתָם שֶׁל נוֹגְדֵי הַכְּאֵבִים הַטִּבְעִיִּים שֶׁל הַמּוֹחַ -\n",
      "רצוי:  גּוּפָנִי: הֵן מְחַקּוֹת אֶת פְּעִילוּתָם שֶׁל נוֹגְדֵי הַכְּאֵבִים הַטִּבְעִיִּים שֶׁל הַמּוֹחַ -\n",
      "\n",
      "מצוי:  מִתְנַגֶּדֶת לְמִּשְׁפָּט חוֹזֵר לְרוֹמֶן זָדוֹרוֹב, שֶׁהוּרְשַׁע בְּרֶצַח תָּאִיר רָאדָה בַּפָרָשָׁה\n",
      "רצוי:  מִתְנַגֶּדֶת לְמִשְׁפָּט חוֹזֵר לְרוֹמָן זָדוֹרוֹב, שֶׁהוּרְשַׁע בְּרֶצַח תָּאִיר רָאדָה בַּפָּרָשָׁה\n",
      "\n",
      "מצוי:  אֶחְתּוֹם וְאָבִיא לָכֶם אֶת זֶה לְשֵׁם, זֶה חָמֵשׁ דַּקּוֹת בָּרֶגֶל. הִיא אָמְרָה לֹא, מָה\n",
      "רצוי:  אֶחְתּוֹם וְאָבִיא לָכֶם אֶת זֶה לְשָׁם, זֶה חָמֵשׁ דַּקּוֹת בָּרֶגֶל. הִיא אָמְרָה לֹא, מָה\n",
      "\n",
      "מצוי:  חֲשׁוּבִים. זֶה דָּבָר מַדְהִים\". וּכְכָל שֶׁהַיְּלָדִים גְּדֵלִים כָּךְ הֵם זוֹכִים לְיוֹתֵר\n",
      "רצוי:  חֲשׁוּבִים. זֶה דָּבָר מַדְהִים\". וּכְכָל שֶׁהַיְּלָדִים גְּדֵלִים כָּךְ הֵם זוֹכִים לְיוֹתֵר\n",
      "\n",
      "מצוי:  אֶת מֶשֶׁךְ הַזְּמַן שֶׁבּוֹ הָעוֹרֶף הָאֶזְרָחִי עָלוּל לִסְפּוֹג. הַהֶרֶס בְּדַאחִיָיה בְּמִלְחֶמֶת\n",
      "רצוי:  אֶת מֶשֶׁךְ הַזְּמַן שֶׁבּוֹ הָעוֹרֶף הָאֶזְרָחִי עָלוּל לִסְפּוֹג. הַהֶרֶס בְּדַאחְיַיה בְּמִלְחֶמֶת\n",
      "\n",
      "מצוי:  הִינָּה בְּמִשְׂרָה מְלֵאָה, כּוֹלֵל יְמֵי שִׁישִּׁי - נְכוֹנוֹת לְשָׁעוֹת נוֹסָפוֹת. דְּרִישׁוֹת:\n",
      "רצוי:  הִינָּהּ בְּמִשְׂרָה מְלֵאָה, כּוֹלֵל יְמֵי שִׁישִּׁי - נְכוֹנוֹת לְשָׁעוֹת נוֹסָפוֹת. דְּרִישׁוֹת:\n",
      "\n",
      "מצוי:  שִׁינָּה עָדִיף לִקְרוֹא סֵפֶר וְלִשְׁמוֹעַ מוּזִיקָה\". אוֹסְפִים חֲפָצִים אוֹ מְשַׁחְרָרִים\n",
      "רצוי:  שינה עדיף לקרוא ספר ולשמוע מוזיקה\". אוספים חפצים או משחררים\n",
      "\n",
      "מצוי:  דַּרְסְטִי, מָה שֶׁכַּמּוּבָן מְקַצֵּר אֶת מֶשֶׁךְ הַלְּחִימָה וְאֶת הַזְּמַן שֶׁבּוֹ הָעוֹרֶף סוֹפֵּג אֵשׁ.\n",
      "רצוי:  דְּרַסְטִי, מָה שֶׁכַּמּוּבָן מְקַצֵּר אֶת מֶשֶׁךְ הַלְּחִימָה וְאֶת הַזְּמַן שֶׁבּוֹ הָעוֹרֶף סוֹפֵג אֵשׁ.\n",
      "\n",
      "מצוי:  פֶּרֶק ב'. אָרִיק (55) הוּא קַבְּלָן בִּנְיָין מֵחוֹלוֹן, וּמִנְּשׂוּאָיו הָרִאשׁוֹנִים יֵשׁ\n",
      "רצוי:  פֶּרֶק ב'. אָרִיק (55) הוּא קַבְּלַן בִּנְיָין מֵחוֹלוֹן, וּמִנְּשׂוּאָיו הָרִאשׁוֹנִים יֵשׁ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_predictions(data, k):\n",
    "    s = slice(k*BATCH_SIZE, (k+1)*BATCH_SIZE)\n",
    "    batch = data.normalized_validation[s]\n",
    "    prediction = model.predict(batch)\n",
    "    [actual_niqqud, actual_dagesh, actual_sin] = [dataset.from_categorical(prediction[0]), dataset.from_categorical(prediction[1]), dataset.from_categorical(prediction[2])]\n",
    "    [expected_niqqud, expected_dagesh, expected_sin] = [data.niqqud_validation[s], data.dagesh_validation[s], data.sin_validation[s]]\n",
    "    actual = data.merge(batch, ns=actual_niqqud, ds=actual_dagesh, ss=actual_sin)\n",
    "    expected = data.merge(batch, ns=expected_niqqud, ds=expected_dagesh, ss=expected_sin)\n",
    "    for i, (a, e) in enumerate(zip(actual, expected)):\n",
    "        print('מצוי: ', a)\n",
    "        print('רצוי: ', e)\n",
    "        print()\n",
    "\n",
    "print_predictions(load_data(['newspapers'], maxlen=MAXLEN), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
