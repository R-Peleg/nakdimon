{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import dataset\n",
    "assert tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 64, 512)      22528       input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 64, 256)      1574912     embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 64, 256)      1050624     bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 64, 256)      0           bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 64, 16)       4112        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 64, 3)        771         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 64, 4)        1028        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "N (Softmax)                     (None, 64, 16)       0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "D (Softmax)                     (None, 64, 3)        0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "S (Softmax)                     (None, 64, 4)        0           dense_26[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,653,975\n",
      "Trainable params: 2,653,975\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAXLEN = 64\n",
    "\n",
    "def build_model():\n",
    "    EMBED_DIM = 512\n",
    "    UNITS = 256\n",
    "\n",
    "    LETTERS_SIZE = len(dataset.letters_table)\n",
    "    NIQQUD_SIZE = len(dataset.niqqud_table)\n",
    "    DAGESH_SIZE = len(dataset.dagesh_table)\n",
    "    SIN_SIZE = len(dataset.sin_table)\n",
    "\n",
    "    common_input = tf.keras.Input(batch_shape=(None, MAXLEN), batch_size=BATCH_SIZE)\n",
    "    \n",
    "    common = layers.Embedding(LETTERS_SIZE, EMBED_DIM, mask_zero=True)(common_input)\n",
    "    common = layers.Bidirectional(layers.LSTM(UNITS, return_sequences=True, dropout=0.1), merge_mode='sum')(common)\n",
    "    common = layers.add([common,\n",
    "                         layers.Bidirectional(layers.LSTM(UNITS, return_sequences=True, dropout=0.1), merge_mode='sum')(common)])\n",
    "\n",
    "    outputs = [\n",
    "        layers.Softmax(name='N')(layers.Dense(NIQQUD_SIZE)(common)),\n",
    "        layers.Softmax(name='D')(layers.Dense(DAGESH_SIZE)(common)),\n",
    "        layers.Softmax(name='S')(layers.Dense(SIN_SIZE)(common))\n",
    "    ]\n",
    "    model = tf.keras.Model(inputs=[common_input], outputs=outputs)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    tf.keras.utils.plot_model(model, to_file='model.png')\n",
    "    model.summary()\n",
    "    return model\n",
    "    \n",
    "model = build_model()\n",
    "model.save_weights('./checkpoints/uninit')\n",
    "\n",
    "def fit(data, learning_rates):\n",
    "    x  = data.normalized_texts\n",
    "    vx = data.normalized_validation\n",
    "    y  = {'N': data.niqqud_texts,      'D': data.dagesh_texts,      'S': data.sin_texts,      'C': data.normalized_texts     }\n",
    "    vy = {'N': data.niqqud_validation, 'D': data.dagesh_validation, 'S': data.sin_validation, 'C': data.normalized_validation}\n",
    "    return model.fit(x, y, validation_data=(vx, vy), batch_size=BATCH_SIZE, epochs=len(learning_rates),\n",
    "          callbacks=[\n",
    "              tf.keras.callbacks.LearningRateScheduler(lambda epoch, lr: learning_rates[epoch], verbose=0),\n",
    "              # tf.keras.callbacks.ModelCheckpoint(filepath='checkpoints/ckpt_{epoch}', save_weights_only=True),\n",
    "          ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(source, maxlen=MAXLEN):\n",
    "    filenames = [os.path.join('texts', f) for f in source]\n",
    "    return dataset.load_file(filenames, BATCH_SIZE, 0.1, maxlen=maxlen, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rabanit = load_data(['birkat_hamazon.txt', 'kuzari.txt', 'hakdama_leorot.txt', 'hartzaat_harav.txt', 'orhot_hayim.txt', 'rambam_mamre.txt', 'short_table.txt', 'tomer_dvora.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre_modern = load_data(['elef_layla.txt', 'bialik', 'shaul_tchernichovsky', 'breslev.txt', 'itzhak_berkman', 'zevi_scharfstein', 'pesah_kaplan', 'abraham_regelson',\n",
    "                             'elisha_porat', 'uriel_ofek', 'yisrael_dushman', 'zvi_zviri', 'atar_hashabat.txt', 'ali_baba.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modern = load_data(['forums', 'newspapers', 'wiki', 'blogs', 'sipurim.txt', 'ricky.txt', 'imagination.txt', 'adamtsair.txt', 'katarsis.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76377 samples, validate on 8487 samples\n",
      "Epoch 1/2\n",
      "76377/76377 [==============================] - 99s 1ms/sample - loss: 0.2589 - N_loss: 0.2000 - D_loss: 0.0526 - S_loss: 0.0062 - N_accuracy: 0.9305 - D_accuracy: 0.9802 - S_accuracy: 0.9983 - val_loss: 0.1447 - val_N_loss: 0.1093 - val_D_loss: 0.0327 - val_S_loss: 0.0027 - val_N_accuracy: 0.9625 - val_D_accuracy: 0.9882 - val_S_accuracy: 0.9994\n",
      "Epoch 2/2\n",
      "76377/76377 [==============================] - 100s 1ms/sample - loss: 0.1085 - N_loss: 0.0803 - D_loss: 0.0259 - S_loss: 0.0023 - N_accuracy: 0.9729 - D_accuracy: 0.9907 - S_accuracy: 0.9995 - val_loss: 0.1081 - val_N_loss: 0.0801 - val_D_loss: 0.0257 - val_S_loss: 0.0022 - val_N_accuracy: 0.9730 - val_D_accuracy: 0.9907 - val_S_accuracy: 0.9995\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('./checkpoints/uninit')\n",
    "history = fit(data_rabanit, [3e-3, 3e-4])\n",
    "model.save_weights('./checkpoints/rabanit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84096 samples, validate on 9344 samples\n",
      "Epoch 1/2\n",
      "84096/84096 [==============================] - 110s 1ms/sample - loss: 0.2576 - N_loss: 0.1936 - D_loss: 0.0579 - S_loss: 0.0061 - N_accuracy: 0.9346 - D_accuracy: 0.9767 - S_accuracy: 0.9984 - val_loss: 0.2116 - val_N_loss: 0.1559 - val_D_loss: 0.0505 - val_S_loss: 0.0052 - val_N_accuracy: 0.9481 - val_D_accuracy: 0.9799 - val_S_accuracy: 0.9986\n",
      "Epoch 2/2\n",
      "84096/84096 [==============================] - 105s 1ms/sample - loss: 0.1743 - N_loss: 0.1268 - D_loss: 0.0431 - S_loss: 0.0044 - N_accuracy: 0.9574 - D_accuracy: 0.9828 - S_accuracy: 0.9988 - val_loss: 0.1744 - val_N_loss: 0.1263 - val_D_loss: 0.0437 - val_S_loss: 0.0044 - val_N_accuracy: 0.9580 - val_D_accuracy: 0.9829 - val_S_accuracy: 0.9989\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('./checkpoints/rabanit')\n",
    "history = fit(data_pre_modern, [3e-3, 3e-4])\n",
    "model.save_weights('./checkpoints/pre_modern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9964 samples, validate on 1108 samples\n",
      "Epoch 1/2\n",
      "9964/9964 [==============================] - 13s 1ms/sample - loss: 0.2417 - N_loss: 0.1789 - D_loss: 0.0569 - S_loss: 0.0058 - N_accuracy: 0.9450 - D_accuracy: 0.9777 - S_accuracy: 0.9987 - val_loss: 0.1945 - val_N_loss: 0.1422 - val_D_loss: 0.0472 - val_S_loss: 0.0047 - val_N_accuracy: 0.9564 - val_D_accuracy: 0.9811 - val_S_accuracy: 0.9989\n",
      "Epoch 2/2\n",
      "9964/9964 [==============================] - 13s 1ms/sample - loss: 0.1449 - N_loss: 0.1044 - D_loss: 0.0365 - S_loss: 0.0039 - N_accuracy: 0.9689 - D_accuracy: 0.9859 - S_accuracy: 0.9990 - val_loss: 0.1746 - val_N_loss: 0.1268 - val_D_loss: 0.0431 - val_S_loss: 0.0043 - val_N_accuracy: 0.9616 - val_D_accuracy: 0.9826 - val_S_accuracy: 0.9990\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('./checkpoints/pre_modern')\n",
    "history = fit(data_modern, [3e-3, 3e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "for n, v in enumerate(['accuracy', 'loss'], 0):\n",
    "    for n1, t in enumerate(['D', 'N'], 0):\n",
    "        p = ax[n][n1]\n",
    "        p.plot(history.history[t + '_' + v][0:])\n",
    "        p.plot(history.history['val_' + t + '_' +  v][0:])\n",
    "        p.legend([t + '_Train', t + '_Test'], loc='center right')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "tfjs.converters.save_keras_model(model, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "מצוי:  עֲשׂוּיוֹת לְמִידַּת מִדְיוּם-רַיֵיר, מֵעַל רוֹטֶב \"טוֹפִי יָפְנִי\", שֶׁעִיקְּרוּ חֶמְאָה\n",
      "רצוי:  עֲשׂוּיוֹת לְמִידַּת מֶדְיוּם-רֵייר, מֵעַל רוֹטֶב \"טוֹפִי יַפָּנִי\", שֶׁעִיקָּרוֹ חֶמְאָה\n",
      "\n",
      "מצוי:  שֶׁנִּמְצְאוּ בִּצְפוֹן הָהָר, עִם שֵׁמוֹת בְּעִבְרִית וּבֵינֵיהֶם \"בֶּן יָאִיר\". לֹא מִן הַנִּמְנָע\n",
      "רצוי:  שֶׁנִּמְצְאוּ בִּצְפוֹן הָהָר, עִם שֵׁמוֹת בְּעִבְרִית וּבֵינֵיהֶם \"בֶּן יָאִיר\". לֹא מִן הַנִּמְנָע\n",
      "\n",
      "מצוי:  חוּץ מֵהַמְּבְטָא הָרוּסִי הַמְּזוּיָּף, בְּבַקָּשָׁה, דַּי כְּבָר עִם זֶה. הַסְּצָנוֹת שֶׁבָּהֶן הִיא\n",
      "רצוי:  חוּץ מֵהַמִּבְטָא הָרוּסִי הַמְּזוּיָּף, בְּבַקָּשָׁה, דַּי כְּבָר עִם זֶה. הַסְּצֵנוֹת שֶׁבָּהֶן הִיא\n",
      "\n",
      "מצוי:  אֶת הַהוּמוֹר הָעַצְמִי עֵקֶב שִׁימּוּשׁ יֶתֶר בְּחוֹמָרִים מִן הַמּוּכָן, נִגְלָה שֶׁהַקְּלִישָׁאוֹת\n",
      "רצוי:  אֶת הַהוּמוֹר הָעַצְמִי עֵקֶב שִׁימּוּשׁ יֶתֶר בְּחוֹמָרִים מִן הַמּוּכָן, נִגְלֶה שֶׁהַקְּלִישָׁאוֹת\n",
      "\n",
      "מצוי:  נוֹסֶפֶת, הַפַּעַם שְׂמֹאלָה לְמֶרְכַּז הָעִיר, יֶשְׁנָם אֲנָשִׁים רַבִּים אֲבָל מִתּוֹךְ כּוּלָּם,\n",
      "רצוי:  נוֹסֶפֶת, הַפַּעַם שְׂמֹאלָה לְמֶרְכַּז הָעִיר, יֶשְׁנָם אֲנָשִׁים רַבִּים אֲבָל מִתּוֹךְ כּוּלָּם,\n",
      "\n",
      "מצוי:  הִיא כָּזֹאת רְאוּוֹתָנִית וַעֲדַיִין מַצְלִיחָה לַחֲמוֹק בְּכָל פַּעַם. וִילְנֵל, הָרוֹצַחַת\n",
      "רצוי:  הִיא כְּזֹאת רַאַוְותָנִית וַעֲדַיִין מַצְלִיחָה לַחֲמוֹק בְּכָל פַּעַם. וִילְנָל, הָרוֹצַחַת\n",
      "\n",
      "מצוי:  הַדְּרוֹמִי שֶׁל הַגִּזְרָה הַצְּפוֹנִית). בְּמַקְבִּיל, הֵחֵלּוּ כּוֹחוֹת שִׁרְיוֹן מִצְרִיִּים\n",
      "רצוי:  הַדְּרוֹמִי שֶׁל הַגִּזְרָה הַצְּפוֹנִית). בְּמַקְבִּיל, הֵחֵלּוּ כּוֹחוֹת שִׁרְיוֹן מִצְרִיִּים\n",
      "\n",
      "מצוי:  וּמִסְתַּכְּלוֹת דֶּרֶךְ הַכַּוֶוֹנֶת, הַקָּלִיעַ שָׁעָף בִּמְהִירוּת, עוֹשָׂה אֶת דַּרְכּוֹ בֵּין עָלִים,\n",
      "רצוי:  וּמִסְתַּכְּלוֹת דֶּרֶךְ הַכַּוֶּונֶת, הַקָּלִיעַ שֶׁעָף בִּמְהִירוּת, עוֹשָׂה אֶת דַּרְכּוֹ בֵּין עָלִים,\n",
      "\n",
      "מצוי:  הַנְּכוֹנוּת שֶׁלּוֹ לְהַקְרִיב אֶת גּוּפוֹ לְטוֹבַת הַקְּבוּצָה, אוֹ בְּמִילִּים אֲחֵרוֹת,\n",
      "רצוי:  הַנְּכוֹנוּת שֶׁלּוֹ לְהַקְרִיב אֶת גּוּפוֹ לְטוֹבַת הַקְּבוּצָה, אוֹ בְּמִילִּים אֲחֵרוֹת,\n",
      "\n",
      "מצוי:  שְׁקִיִּים בֵּין שְׁתֵיהֶן), עַל הַשְּׁטָחִים הַמְּדוּבָּרִים (אוֹ חֲלָקִים מֵהֶם) גַּם בַּמִישׁוֹר\n",
      "רצוי:  שֶׁקַּיָּים בֵּין שְׁתֵּיהֶן), עַל הַשְּׁטָחִים הַמְּדוּבָּרִים (אוֹ חֲלָקִים מֵהֶם) גַּם בַּמִּישׁוֹר\n",
      "\n",
      "מצוי:  אַרְבַּע שָׁנִים לְאַחַר תּוֹם הַחֲפִירוֹת, שֶׁהַנְּצוּרִים בִּמְצָדָה לֹא הָיוּ לוֹחֲמֵי חֵירוֹת,\n",
      "רצוי:  אַרְבַּע שָׁנִים לְאַחַר תּוֹם הַחֲפִירוֹת, שֶׁהַנְּצוּרִים בִּמְצָדָה לֹא הָיוּ לוֹחֲמֵי חֵירוּת,\n",
      "\n",
      "מצוי:  חֲסִימוֹת לֹא תָּמִיד זוֹכֶה לִקְרֵדִיט הָרָאוּי, כִּי הֵן לֹא נִרְשָׁמוֹת בְּבּוֹקְס סְקוֹר.\n",
      "רצוי:  חֲסִימוֹת לֹא תָּמִיד זוֹכֶה לַקְּרֵדִיט הָרָאוּי, כִּי הֵן לֹא נִרְשָׁמוֹת בַּבּוֹקְס סְקוֹר.\n",
      "\n",
      "מצוי:  הַקּוֹלֶקְטִיבִית שֶׁהִתְרַחֲשָׁה בִּמְצָדָה. יוֹצְאֵי דּוֹפֶן הֵם שְׂרִידִים שֶׁל גּוּפוֹת שֶׁנִּמְצְאוּ\n",
      "רצוי:  הַקּוֹלֶקְטִיבִית שֶׁהִתְרַחֲשָׁה בִּמְצָדָה. יוֹצְאֵי דּוֹפֶן הֵם שְׂרִידִים שֶׁל גּוּפוֹת שֶׁנִּמְצְאוּ\n",
      "\n",
      "מצוי:  אֶת הַכּוֹבַע שֶׁלּוֹ וּמֵנִיחַ עַל מַחֲזִיק הַמַּפִּיּוֹת הַצָּמוּד לַקִּיר כָּךְ שֶׁהוּא יַסְתִּיר אֶת\n",
      "רצוי:  אֶת הַכּוֹבַע שֶׁלּוֹ וּמַנִּיחַ עַל מַחֲזִיק הַמַּפִּיּוֹת הַצָּמוּד לַקִּיר כָּךְ שֶׁהוּא יַסְתִּיר אֶת\n",
      "\n",
      "מצוי:  קוֹזְמָה, שֶׁאוּלַי לֹא קוֹפְצִים בָּרֹאשׁ כְּשַׂחְקָנִים שֶׁרָצִים כָּל כָּךְ הַרְבֵּה, אַךְ\n",
      "רצוי:  קוֹזְמָה, שֶׁאוּלַי לֹא קוֹפְצִים בָּרֹאשׁ כְּשַׂחְקָנִים שֶׁרָצִים כָּל כָּךְ הַרְבֵּה, אַךְ\n",
      "\n",
      "מצוי:  לְלַחַץ גָּדַל וְהוֹלֵךְ לְהַפְחִית עֲלוּיוֹת. יֵשׁ גַּם לַחַץ לְהָאִיץ אֶת הַפִּיתּוּחַ\n",
      "רצוי:  לְלַחַץ גָּדֵל וְהוֹלֵךְ לְהַפְחִית עֲלוּיוֹת. יֵשׁ גַּם לַחַץ לְהָאִיץ אֶת הַפִּיתּוּחַ\n",
      "\n",
      "מצוי:  אַחַת יְכוֹלָה לְסַיֵּים אֶת תַּפְקִידָהּ הַהִיסְטוֹרִי אֲבָל יֵשׁ לָנוּ לְפָנֵינוּ עוֹד דֶּרֶךְ\n",
      "רצוי:  אַחַת יְכוֹלָה לְסַיֵּים אֶת תַּפְקִידָהּ הַהִיסְטוֹרִי אֲבָל יֵשׁ לָנוּ לְפָנֵינוּ עוֹד דֶּרֶךְ\n",
      "\n",
      "מצוי:  בֶּן יְהוּדָה\". יָדִין עַצְמוֹ כּוֹתֵב: \"בִּשְׁנַת 55 הֶחְלִיט פְּלָאוּׂויוּס סִילְווֹה, לְחַסֵּל\n",
      "רצוי:  בֶּן יְהוּדָה\". יָדִין עַצְמוֹ כּוֹתֵב: \"בִּשְׁנַת 55 הֶחֱלִיט פְּלָאוִׂויוּס סִילְוָוֹה, לְחַסֵּל\n",
      "\n",
      "מצוי:  בִּכְתַב-הָעֵת הַמַּדָּעִי OOOO הָעַיִן וַעֲצַבִּי הָרְאִיָּה בִּקְלִיפַּת הַמּוֹחַ. אִיּוּר:\n",
      "רצוי:  בִּכְתַב-הָעֵת הַמַּדָּעִי OOOO הָעַיִן וַעֲצַבִּי הָרְאִיָּה בִּקְלִיפַּת הַמּוֹחַ. אִיּוּר:\n",
      "\n",
      "מצוי:  בִּמְדִינוֹת הַמְּגַבְּשׁוֹת אֶת זֶהוּתָן. אוּלָם, תּוֹפָעָה זוֹ שֶׁל גִּיּוּס הָאַרְכֵיאוֹלוֹגְיָה\n",
      "רצוי:  בִּמְדִינוֹת הַמְּגַבְּשׁוֹת אֶת זֶהוּתָן. אוּלָם, תּוֹפָעָה זוֹ שֶׁל גִּיּוּס הָאַרְכֵיאוֹלוֹגְיָה\n",
      "\n",
      "מצוי:  אֲבָל מְדוּבָּר בְּאֶקְט שֶׁל פַּחְדָנוּת. אָכֵן, לֹא נִמְצְאוּ בָּאֲתָר שְׂרִידֵי מֵאוֹת\n",
      "רצוי:  אֲבָל מְדוּבָּר בְּאַקְט שֶׁל פַּחְדָנוּת. אָכֵן, לֹא נִמְצְאוּ בַּאֲתַר שְׂרִידֵי מֵאוֹת\n",
      "\n",
      "מצוי:  נֶאֶסְפוּ מִ-55 מוֹסְדוֹת אָקָדֵמִיִּים מוֹבִילִים וְסוֹכְנוּיוֹת שֶׁל הָאוּ\"ם מֵרַחֲבֵי\n",
      "רצוי:  נֶאֶסְפוּ מִ-55 מוֹסָדוֹת אָקָדֵמִיִּים מוֹבִילִים וְסוֹכְנוּיוֹת שֶׁל הָאוּ\"ם מֵרַחֲבֵי\n",
      "\n",
      "מצוי:  הַהֶרְכֵּב הַמְּיוּחָד הַזֶּה OOOOOOOOO, שָׁנוּי בְּמַחֲלוֹקֶת לֹא קְטַנָּה. הַדֵּעוֹת כְּלַפָּיו\n",
      "רצוי:  הַהֶרְכֵּב הַמְּיוּחָד הַזֶּה OOOOOOOOO, שָׁנוּי בְּמַחֲלוֹקֶת לֹא קְטַנָּה. הַדֵּעוֹת כְּלַפָּיו\n",
      "\n",
      "מצוי:  רְאָיוֹת בְּתִיקֵי עֲבֵירוֹת מִין בְּתֵירוּץ שֶׁ\"אֵין מָקוֹם לִשְׁמוֹר עֲרְכוֹת אוֹנֶס\",\n",
      "רצוי:  רְאָיוֹת בְּתִיקֵי עֲבֵירוֹת מִין בְּתֵירוּץ שֶׁ\"אֵין מָקוֹם לִשְׁמוֹר עֶרְכוֹת אוֹנֶס\",\n",
      "\n",
      "מצוי:  הַנָּחָשׁ. יַחַד עִם זֹאת, נִמְצְאוּ עֵדוּיוֹת בְּרוּרוֹת לְיִיצּוּר חִצִים בִּזְמַן הַמֶּרֶד\n",
      "רצוי:  הַנָּחָשׁ. יַחַד עִם זֹאת, נִמְצְאוּ עֵדוּיוֹת בְּרוּרוֹת לְיִיצּוּר חִצִּים בִּזְמַן הַמֶּרֶד\n",
      "\n",
      "מצוי:  אַדִיר שֶׁהִתְבַּטֵּא בְּהֶרֶס בֵּית הַמִּקְדָּשׁ הַשֵּׁנִי וִירוּשָׁלַיִם, בְּהֶרֶג הֲמוֹנִי שֶׁל יְהוּדִים\n",
      "רצוי:  אַדִּיר שֶׁהִתְבַּטֵּא בְּהֶרֶס בֵּית הַמִּקְדָּשׁ הַשֵּׁנִי וִירוּשָׁלַיִם, בְּהֶרֶג הֲמוֹנֵי שֶׁל יְהוּדִים\n",
      "\n",
      "מצוי:  בָּשַׂר טָחוֹן מְשׁוּלָּב עִם רוֹטֶב עַגְבָנִיּוֹת מְתַקְתֵּק וּבָצָל מְטוֹגָּן בְּתוֹךְ לַחֲמָנִיַּית\n",
      "רצוי:  בָּשָׂר טָחוּן מְשׁוּלָּב עִם רוֹטֶב עַגְבָנִיּוֹת מְתַקְתֵּק וּבָצָל מְטוּגָּן בְּתוֹךְ לַחְמָנִיַּית\n",
      "\n",
      "מצוי:  וְנִגְמֶרֶת לוֹ מוּל הָעֵינַיִים. אֲנָשִׁים שֶׁחוֹלְפִים עַל פְּנֵיהֶם, מְסִיבִים רֹאשׁ,\n",
      "רצוי:  וְנִגְמֶרֶת לוֹ מוּל הָעֵינַיִים. אֲנָשִׁים שֶׁחוֹלְפִים עַל פְּנֵיהֶם, מִסִּיבִים רֹאשׁ,\n",
      "\n",
      "מצוי:  בּוֹ כְּדֵי לְאַיִּים עַל חַיֵּי אָדָם וְעַל רְכוּשׁ - כָּאן עַל הָאָרֶץ אוֹ בֶּחָלָל - לִפְנֵי\n",
      "רצוי:  בּוֹ כְּדֵי לְאַיֵּים עַל חַיֵּי אָדָם וְעַל רְכוּשׁ - כָּאן עַל הָאָרֶץ אוֹ בֶּחָלָל - לִפְנֵי\n",
      "\n",
      "מצוי:  מֵהֶם יַעֲבוֹר לְמַעְלָה וְאָז שְׁלִיחַת פְּקוּדּוֹת זְדוֹנִיּוֹת בְּאֶמְצָעוּת אַנְטֵנוֹת קַרְקָעִיּוֹת\n",
      "רצוי:  מֵהֶם יַעֲבוֹר לְמַעְלָה וְאָז שְׁלִיחַת פְּקוּדּוֹת זְדוֹנִיּוֹת בְּאֶמְצָעוּת אַנְטֵנוֹת קַרְקָעִיּוֹת\n",
      "\n",
      "מצוי:  וְעֵינָיו עֲצוּמוֹת. לְשַׁחְרֵר אֶת הָאֲוִויר.\"לַהֲרוֹג אֶת אִיב\" הִיא סִדְרָה דֵּי\n",
      "רצוי:  וְעֵינָיו עֲצוּמוֹת. לְשַׁחְרֵר אֶת הָאֲוִויר.\"לַהֲרוֹג אֶת אִיב\" הִיא סִדְרָה דֵּי\n",
      "\n",
      "מצוי:  בַּעֲבוֹדָה הַזּוֹ. הוּא מַשְׂכִּיל לְהָנִיף אוֹתְךָ לְמַעְלָה לְמַעְלָה וּלְמַטָּה לְמַטָה בְּעֵת\n",
      "רצוי:  בָּעֲבוֹדָה הַזּוֹ. הוּא מַשְׂכִּיל לְהָנִיף אוֹתְךָ לְמַעְלָה לְמַעְלָה וּלְמַטָּה לְמַטָּה בְּעֵת\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_predictions(data, k):\n",
    "    s = slice(k*BATCH_SIZE, (k+1)*BATCH_SIZE)\n",
    "    batch = data.normalized_validation[s]\n",
    "    prediction = model.predict(batch)\n",
    "    [actual_niqqud, actual_dagesh, actual_sin] = [dataset.from_categorical(prediction[0]), dataset.from_categorical(prediction[1]), dataset.from_categorical(prediction[2])]\n",
    "    [expected_niqqud, expected_dagesh, expected_sin] = [data.niqqud_validation[s], data.dagesh_validation[s], data.sin_validation[s]]\n",
    "    actual = data.merge(batch, ns=actual_niqqud, ds=actual_dagesh, ss=actual_sin)\n",
    "    expected = data.merge(batch, ns=expected_niqqud, ds=expected_dagesh, ss=expected_sin)\n",
    "    for i, (a, e) in enumerate(zip(actual, expected)):\n",
    "        print('מצוי: ', a)\n",
    "        print('רצוי: ', e)\n",
    "        print()\n",
    "\n",
    "print_predictions(load_data(['blogs'], maxlen=MAXLEN), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
