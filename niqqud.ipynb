{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 60\n",
    "BATCH_SIZE = 32\n",
    "files = ['texts/' + f for f in os.listdir('texts/') if not f.startswith('.')]\n",
    "\n",
    "data = dataset.load_file(BATCH_SIZE, 0.05, maxlen=MAXLEN, filenames=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 60, 512)      37376       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 60, 400)      2193600     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 60, 400)      1924800     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 60, 400)      0           bidirectional[0][0]              \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 60, 60)       24060       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 60, 60)       24060       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "N (Softmax)                     (None, 60, 60)       0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "D (Softmax)                     (None, 60, 60)       0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,203,896\n",
      "Trainable params: 4,203,896\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBED_DIM = 512\n",
    "UNITS = 400\n",
    "\n",
    "common_input = tf.keras.Input(batch_shape=(None, data.input_texts.shape[1]), batch_size=BATCH_SIZE)\n",
    "common = layers.Embedding(len(data.letters_table), EMBED_DIM, mask_zero=True)(common_input)\n",
    "common = layers.Bidirectional(layers.GRU(UNITS, return_sequences=True, dropout=0.3), merge_mode='sum')(common)\n",
    "\n",
    "common = layers.add([common, layers.Bidirectional(layers.GRU(UNITS, return_sequences=True, dropout=0.1), merge_mode='sum')(common)])\n",
    "\n",
    "niqqud = layers.Softmax(name='N')(layers.Dense(data.niqqud_texts.shape[1])(common))\n",
    "dagesh = layers.Softmax(name='D')(layers.Dense(data.dagesh_texts.shape[1])(common))\n",
    "\n",
    "model = tf.keras.Model(inputs=[common_input], outputs=[niqqud, dagesh])\n",
    "\n",
    "tf.keras.utils.plot_model(model, to_file='model.png')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "def fit(learning_rates):\n",
    "    return model.fit(data.input_texts, [data.niqqud_texts, data.dagesh_texts],\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=len(learning_rates),\n",
    "          validation_data=(data.input_validation, [data.niqqud_validation,  data.dagesh_validation]),\n",
    "          callbacks=[\n",
    "              tf.keras.callbacks.LearningRateScheduler(lambda epoch, lr: learning_rates[epoch], verbose=0),\n",
    "              # tf.keras.callbacks.ModelCheckpoint(filepath='checkpoints/ckpt_{epoch}', save_weights_only=True),\n",
    "          ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 111720 samples, validate on 5880 samples\n",
      "Epoch 1/2\n",
      "111720/111720 [==============================] - 178s 2ms/sample - loss: 0.2937 - N_loss: 0.2323 - D_loss: 0.0614 - N_accuracy: 0.9213 - D_accuracy: 0.9774 - val_loss: 0.1815 - val_N_loss: 0.1402 - val_D_loss: 0.0413 - val_N_accuracy: 0.9532 - val_D_accuracy: 0.9850\n",
      "Epoch 2/2\n",
      " 65760/111720 [================>.............] - ETA: 1:08 - loss: 0.1404 - N_loss: 0.1082 - D_loss: 0.0322 - N_accuracy: 0.9636 - D_accuracy: 0.9880- ETA: 1:09 - loss: 0.1405 - N_loss: 0.1083 - D_loss: 0.0322 - N_accuracy: 0.9635 - D_accurac"
     ]
    }
   ],
   "source": [
    "history = fit([2e-3, 7e-4]) #, 1e-4, 3e-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "for n, v in enumerate(['accuracy', 'loss'], 0):\n",
    "    for n1, t in enumerate(['D', 'N'], 0):\n",
    "        p = ax[n][n1]\n",
    "        p.plot(history.history[t + '_' + v][0:])\n",
    "        p.plot(history.history['val_' + t + '_' +  v][0:])\n",
    "        p.legend([t + '_Train', t + '_Test'], loc='center right')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predictions(k):\n",
    "    s = slice(k*BATCH_SIZE, (k+1)*BATCH_SIZE)\n",
    "    batch = data.input_validation[s]\n",
    "    [actual_niqqud, actual_dagesh] = dataset.from_categorical(model.predict(batch))\n",
    "    [expected_niqqud, expected_dagesh] = [data.niqqud_validation[s], data.dagesh_validation[s]]\n",
    "    actual = data.merge(batch, ns=actual_niqqud, ds=actual_dagesh)\n",
    "    expected = data.merge(batch, ns=expected_niqqud, ds=expected_dagesh)\n",
    "    for i, (a, e) in enumerate(zip(actual, expected)):\n",
    "        print('מצוי: ', a)\n",
    "        print('רצוי: ', e)\n",
    "        print()\n",
    "\n",
    "print_predictions(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
