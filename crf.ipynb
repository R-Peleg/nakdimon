{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import dataset\n",
    "import schedulers\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.config.list_physical_devices('GPU')\n",
    "\n",
    "from tensorflow_addons.layers.crf import CRF\n",
    "from tensorflow_addons.text.crf import crf_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unpack_data(data):\n",
    "    if len(data) == 2:\n",
    "        return data[0], data[1], None\n",
    "    elif len(data) == 3:\n",
    "        return data\n",
    "    else:\n",
    "        raise TypeError(\"Expected data to be a tuple of size 2 or 3.\")\n",
    "\n",
    "\n",
    "class ModelWithCRFLoss(keras.Model):\n",
    "    \"\"\"Wrapper around the base model for custom training logic.\"\"\"\n",
    "\n",
    "    def compute_loss(self, x, y, sample_weights, training=False):\n",
    "        y_pred = self(x, training=training)\n",
    "        # _, potentials, sequence_length, chain_kernel = y_pred\n",
    "        potentials, sequence_length, chain_kernel = y_pred\n",
    "\n",
    "        crf_loss = -crf_log_likelihood(potentials, y, sequence_length, chain_kernel)[0]\n",
    "\n",
    "        if sample_weights is not None:\n",
    "            crf_loss = crf_loss * sample_weights\n",
    "\n",
    "        return tf.reduce_mean(crf_loss), sum(self.losses)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y, sample_weight = unpack_data(data)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            crf_loss, internal_losses = self.compute_loss(\n",
    "                x, y, sample_weight, training=True\n",
    "            )\n",
    "            total_loss = crf_loss + internal_losses\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        return {\"crf_loss\": crf_loss, \"internal_losses\": internal_losses}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y, sample_weight = unpack_data(data)\n",
    "        crf_loss, internal_losses = self.compute_loss(x, y, sample_weight)\n",
    "        return {\"crf_loss_val\": crf_loss, \"internal_losses_val\": internal_losses}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "LETTERS_SIZE = len(dataset.letters_table)\n",
    "NIQQUD_SIZE = len(dataset.niqqud_table)\n",
    "DAGESH_SIZE = len(dataset.dagesh_table)\n",
    "SIN_SIZE = len(dataset.sin_table)\n",
    "\n",
    "def build_model(EMBED_DIM=28, UNITS=253):  # EMBED_DIM=62, UNITS=252  == 2^20\n",
    "    layer = input_text = keras.Input(batch_shape=(None, None), batch_size=BATCH_SIZE)\n",
    "    layer = layers.Embedding(LETTERS_SIZE, EMBED_DIM, input_length=None, mask_zero=True)(layer)\n",
    "    \n",
    "    layer = layers.Dense(UNITS, activation=None)(layer)\n",
    "    \n",
    "    bidi = layers.Bidirectional(layers.LSTM(UNITS, return_sequences=True, dropout=0.0), merge_mode='sum')\n",
    "    layer = bidi(layer)\n",
    "    layer = layers.add([layer, bidi(layer)])\n",
    "\n",
    "    \n",
    "    outputs = [\n",
    "        CRF(NIQQUD_SIZE, name='N')(layer),\n",
    "        CRF(DAGESH_SIZE, name='D')(layer),\n",
    "        CRF(SIN_SIZE, name='S')(layer),\n",
    "    ]\n",
    "    model = ModelWithCRFLoss(inputs=input_text, outputs=outputs)\n",
    "    \n",
    "    outputs = [\n",
    "        layers.Softmax(name='N')(layers.Dense(NIQQUD_SIZE)(layer)),\n",
    "        layers.Softmax(name='D')(layers.Dense(DAGESH_SIZE)(layer)),\n",
    "        layers.Softmax(name='S')(layers.Dense(SIN_SIZE)(layer)),\n",
    "    ]\n",
    "    model = keras.Model(inputs=input_text, outputs=outputs)\n",
    "    model.build((None, MAXLEN))\n",
    "\n",
    "    jsmodel = model \n",
    "    keras.utils.plot_model(model, to_file='model.png')\n",
    "    return model, jsmodel\n",
    "\n",
    "model, jsmodel = build_model()\n",
    "\n",
    "model.summary()\n",
    "model.save_weights('./checkpoints/crf_uninit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    K = keras.backend\n",
    "    f = K.floatx()\n",
    "    # convert dense predictions to labels\n",
    "    y_pred_labels =  K.cast(K.argmax(y_pred, axis=-1), f)\n",
    "    \n",
    "    res = K.cast(K.equal(y_true, y_pred_labels), f)\n",
    "    return K.sum(res) / K.sum(K.cast(K.not_equal(y_true, 0), f))\n",
    "\n",
    "\n",
    "def fit(train_validation, scheduler=None, verbose=1, lr=1e-4):\n",
    "    train, valid = train_validation\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[accuracy])\n",
    "    callbacks = []\n",
    "    if isinstance(scheduler, schedulers.CircularLearningRate):\n",
    "        scheduler.set_dataset(train, BATCH_SIZE)\n",
    "    if scheduler:\n",
    "        callbacks.append(scheduler)\n",
    "        \n",
    "    x  = train.normalized\n",
    "    vx = valid.normalized\n",
    "    \n",
    "    y  = {'N': train.niqqud, 'D': train.dagesh, 'S': train.sin }\n",
    "    vy = {'N': valid.niqqud, 'D': valid.dagesh, 'S': valid.sin }\n",
    "    \n",
    "    return model.fit(x, y, validation_data=(vx, vy), batch_size=BATCH_SIZE, epochs=1, verbose=verbose, callbacks=callbacks)\n",
    "\n",
    "\n",
    "MAXLEN = 82\n",
    "def load_data(source, maxlen=MAXLEN, validation=0.1):\n",
    "    filenames = [os.path.join('texts', f) for f in source]\n",
    "    train, valid = dataset.load_data(filenames, validation, maxlen=maxlen)\n",
    "    return train, valid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
