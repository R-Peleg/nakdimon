{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import dataset\n",
    "import schedulers\n",
    "\n",
    "assert tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_metric(v, y_true):\n",
    "    mask = tf.math.not_equal(y_true, 0)\n",
    "    return tf.reduce_sum(tf.boolean_mask(v, mask)) / tf.cast(tf.math.count_nonzero(mask), tf.float32)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return masked_metric(tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred), y_true)\n",
    "\n",
    "def sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    return masked_metric(tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True), y_true)\n",
    "\n",
    "def get_xy(d):\n",
    "    if d is None:\n",
    "        return None\n",
    "    d.shuffle()\n",
    "    x = d.normalized\n",
    "    y = {'N': d.niqqud, 'D': d.dagesh, 'S': d.sin }\n",
    "    return (x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {}\n",
    "corpus['mix'] = dataset.read_corpora([\n",
    "    'hebrew_diacritized_private/poetry',\n",
    "    'hebrew_diacritized_private/rabanit',\n",
    "    'hebrew_diacritized_private/pre_modern'])\n",
    "\n",
    "corpus['modern'] = dataset.read_corpora([\n",
    "    'hebrew_diacritized/modern'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 90\n",
    "\n",
    "data = {}\n",
    "np.random.seed(2)\n",
    "data['mix'] = dataset.load_data(corpus['mix'], validation_rate=0.01, maxlen=MAXLEN)\n",
    "np.random.seed(2)\n",
    "data['modern'] = dataset.load_data(corpus['modern'], validation_rate=0.1, maxlen=MAXLEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTERS_SIZE = len(dataset.letters_table)\n",
    "NIQQUD_SIZE = len(dataset.niqqud_table)\n",
    "DAGESH_SIZE = len(dataset.dagesh_table)\n",
    "SIN_SIZE = len(dataset.sin_table)\n",
    "\n",
    "def build_model(units):\n",
    "    inp = keras.Input(shape=(None,), batch_size=None)\n",
    "    embed = layers.Embedding(LETTERS_SIZE, units, mask_zero=True)(inp)\n",
    "    \n",
    "    layer = layers.Bidirectional(layers.LSTM(units, return_sequences=True, dropout=0.1), merge_mode='sum')(embed)\n",
    "    layer = layers.Bidirectional(layers.LSTM(units, return_sequences=True, dropout=0.1), merge_mode='sum')(layer)\n",
    "    layer = layers.Dense(units)(layer)\n",
    "\n",
    "    outputs = [\n",
    "        layers.Dense(NIQQUD_SIZE, name='N')(layer),\n",
    "        layers.Dense(DAGESH_SIZE, name='D')(layer),\n",
    "        layers.Dense(SIN_SIZE, name='S')(layer),\n",
    "    ]\n",
    "    return keras.Model(inputs=inp, outputs=outputs)\n",
    "\n",
    "\n",
    "def real_evaluation(model, data, s=slice(0, None), print_comparison=True):\n",
    "    batch = data.normalized[s]\n",
    "    prediction = model.predict(batch)\n",
    "    [actual_niqqud, actual_dagesh, actual_sin] = [dataset.from_categorical(prediction[0]), dataset.from_categorical(prediction[1]), dataset.from_categorical(prediction[2])]\n",
    "    [expected_niqqud, expected_dagesh, expected_sin] = [data.niqqud[s], data.dagesh[s], data.sin[s]]\n",
    "    actual_niqqud[expected_niqqud==0] = 0\n",
    "    actual_dagesh[expected_dagesh==0] = 0\n",
    "    actual_sin[expected_sin==0] = 0\n",
    "    actual = dataset.merge(data.text[s], batch, actual_niqqud, actual_dagesh, actual_sin)\n",
    "    expected = dataset.merge(data.text[s], batch, expected_niqqud, expected_dagesh, expected_sin)\n",
    "    total_decisions = []\n",
    "    total_words = []\n",
    "    total_letters = []\n",
    "    for i, (b, a, e) in enumerate(zip(batch, actual, expected)):\n",
    "        decisions = []\n",
    "        decisions.extend(expected_niqqud[i][expected_niqqud[i]>0] == actual_niqqud[i][expected_niqqud[i]>0])\n",
    "        decisions.extend(expected_dagesh[i][expected_dagesh[i]>0] == actual_dagesh[i][expected_dagesh[i]>0])\n",
    "        decisions.extend(expected_sin[i][expected_sin[i]>0] == actual_sin[i][expected_sin[i]>0])\n",
    "        total_decisions.extend(decisions)\n",
    "        \n",
    "\n",
    "        either = (expected_niqqud[i]>0) | (expected_dagesh[i]>0) | (expected_sin[i]>0)\n",
    "        letters = ((expected_niqqud[i][either] == actual_niqqud[i][either])\n",
    "                 & (expected_dagesh[i][either] == actual_dagesh[i][either])\n",
    "                 & (expected_sin[i][either]    == actual_sin[i][either]))\n",
    "        total_letters.extend(letters)\n",
    "        \n",
    "        words = []\n",
    "        for aw, ew in zip(a.split(), e.split()):\n",
    "            if len([x for x in 'אבגדהוזחטיכלמנסעפצקרשתךםןףץ' if x in aw]) > 1:\n",
    "                words.append(aw == ew)\n",
    "                if print_comparison and aw != ew:\n",
    "                    print(aw, ew)\n",
    "        total_words.extend(words)\n",
    "        \n",
    "        if print_comparison:\n",
    "            print('מצוי: ', a)\n",
    "            print('רצוי: ', e)\n",
    "            print(f'letters: {np.mean(letters):.2%} ({len(letters)-np.sum(letters)} out of {len(letters)})')\n",
    "            print(f'decisions: {np.mean(decisions):.2%} ({len(decisions)-np.sum(decisions)} out of {len(decisions)})')\n",
    "            print(f'words: {np.mean(words):.2%} ({len(words)-np.sum(words)} out of {len(words)})')\n",
    "            print()\n",
    "    letters = np.mean(total_letters)\n",
    "    decisions = np.mean(total_decisions)\n",
    "    words = np.mean(total_words)\n",
    "    print(f'letters: {letters:.2%}, decisions: {decisions:.2%}, words: {words:.2%}')\n",
    "    return (letters, decisions, words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_MODE=run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: elazarg (use `wandb login --relogin` to force relogin)\n",
      "wandb: Tracking run with wandb version 0.10.2\n",
      "wandb: Run data is saved locally in wandb\\run-20200929_024148-1fwyo942\n",
      "wandb: Syncing run feasible-star-577\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/elazarg/dotter\" target=\"_blank\">https://wandb.ai/elazarg/dotter</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/elazarg/dotter/runs/1fwyo942\" target=\"_blank\">https://wandb.ai/elazarg/dotter/runs/1fwyo942</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 172/1684 [==>...........................] - ETA: 2:45 - loss: 1.7535 - N_loss: 1.1492 - D_loss: 0.2992 - S_loss: 0.3051 - N_accuracy: 0.5959 - D_accuracy: 0.8823 - S_accuracy: 0.9095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish, PID 12624\n",
      "wandb: Program failed with code 1.  Press ctrl-c to abort syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:                                                                                \n",
      "wandb: Find user logs for this run at: wandb\\run-20200929_024148-1fwyo942\\logs\\debug.log\n",
      "wandb: Find internal logs for this run at: wandb\\run-20200929_024148-1fwyo942\\logs\\debug-internal.log\n",
      "wandb: Run summary:\n",
      "wandb:         loss 1.847490668296814\n",
      "wandb:       N_loss 1.2139792442321777\n",
      "wandb:       D_loss 0.3158261179924011\n",
      "wandb:       S_loss 0.31768524646759033\n",
      "wandb:   N_accuracy 0.5741077065467834\n",
      "wandb:   D_accuracy 0.8764153122901917\n",
      "wandb:   S_accuracy 0.905684232711792\n",
      "wandb:        _step 3\n",
      "wandb:     _runtime 37\n",
      "wandb:   _timestamp 1601336547\n",
      "wandb: Run history:\n",
      "wandb:         loss █▃▂▁\n",
      "wandb:       N_loss █▄▂▁\n",
      "wandb:       D_loss █▂▂▁\n",
      "wandb:       S_loss █▂▁▁\n",
      "wandb:   N_accuracy ▁▆▇█\n",
      "wandb:   D_accuracy ▁███\n",
      "wandb:   S_accuracy ▁███\n",
      "wandb:        _step ▁▃▆█\n",
      "wandb:     _runtime ▁▃▆█\n",
      "wandb:   _timestamp ▁▃▆█\n",
      "wandb: Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "wandb: \n",
      "wandb: Synced feasible-star-577: https://wandb.ai/elazarg/dotter/runs/1fwyo942\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": " [_Derived_]RecvAsync is cancelled.\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_111}}]]\n\t [[gradient_tape/functional_1/embedding/embedding_lookup/Reshape/_108]] [Op:__inference_train_function_30051]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-01879d95a5a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# 20-30-20-5-1: 88.08-88.16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-01879d95a5a0>\u001b[0m in \u001b[0;36mexperiment\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m     44\u001b[0m                                            log_weights=False)\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             history = model.fit(x, y, validation_data=validation_data,\n\u001b[0m\u001b[0;32m     47\u001b[0m                                 \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                                 \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCancelledError\u001b[0m:  [_Derived_]RecvAsync is cancelled.\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_111}}]]\n\t [[gradient_tape/functional_1/embedding/embedding_lookup/Reshape/_108]] [Op:__inference_train_function_30051]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_MODE run\n",
    "\n",
    "def experiment(n):\n",
    "    BATCH_SIZE = 64\n",
    "    UNITS = 400\n",
    "    np.random.seed(2)\n",
    "    model = build_model(units=UNITS)\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  metrics=accuracy)\n",
    "\n",
    "#     model.save_weights('./checkpoints/uninit')\n",
    "#     model.load_weights('./checkpoints/mix')\n",
    "    \n",
    "    modern_lrs = [30e-4, 30e-4, 30e-4,  8e-4, 1e-4]\n",
    "    \n",
    "    config = {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'maxlen': MAXLEN,\n",
    "        'units': UNITS,\n",
    "        'experiment_id': n,\n",
    "        'order': [\n",
    "              ('mix',    0, 1, schedulers.CircularLearningRate(3e-3, 8e-3, 0e-4, data['mix'][0], BATCH_SIZE), 'mix'),\n",
    "              ('modern', 1, (1 + len(modern_lrs)), tf.keras.callbacks.LearningRateScheduler(lambda epoch, lr: modern_lrs[epoch - 1]), 'modern'),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    run = wandb.init(project=\"dotter\",\n",
    "                     group=f\"{MAXLEN=} 30:80:0, \" + '-'.join(f'{lr}' for lr in modern_lrs),\n",
    "#                      name=f'30-80-0, 20-30-20-5-1',\n",
    "                     tags=[],\n",
    "                     config=config)\n",
    "    with run:\n",
    "        for kind, initial_epoch, epochs, scheduler, save in config['order']:\n",
    "            train, validation = data[kind]\n",
    "\n",
    "            training_data = (x, y) = get_xy(train)\n",
    "            validation_data = get_xy(validation)\n",
    "\n",
    "            wandb_callback = WandbCallback(log_batch_frequency=50,  # int(len(train.normalized) / BATCH_SIZE / 100),\n",
    "                                           training_data=training_data,\n",
    "                                           validation_data=validation_data,\n",
    "                                           save_model=False,\n",
    "                                           log_weights=False)\n",
    "            \n",
    "            history = model.fit(x, y, validation_data=validation_data,\n",
    "                                initial_epoch=initial_epoch,\n",
    "                                epochs=epochs,\n",
    "                                batch_size=BATCH_SIZE, verbose=1,\n",
    "                                callbacks=[wandb_callback, scheduler])\n",
    "            \n",
    "            letters, decisions, words = real_evaluation(model, data['modern'][1], s=slice(0, None), print_comparison=False)\n",
    "            model.save_weights('./checkpoints/' + save)\n",
    "        run.log({'index': 0, 'letters': letters, 'decisions': decisions, 'words': words})\n",
    "    return model\n",
    "\n",
    "for n in range(5):\n",
    "    model = experiment(n)   # 20-30-20-5-1: 88.08-88.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(units=512)\n",
    "model.load_weights('./checkpoints/modern_over2')\n",
    "\n",
    "model.compile()\n",
    "model.save('models/modern.h5')\n",
    "tfjs.converters.save_keras_model(model, 'models/')\n",
    "\n",
    "# hack around tfjs bug:\n",
    "with open('models/model.json', encoding='utf8', mode='r') as f:\n",
    "    text = f.read().replace('\"Functional\"', '\"Model\"')\n",
    "with open('models/model.json', encoding='utf8', mode='w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3)\n",
    "\n",
    "for n, v in enumerate(['accuracy', 'loss'], 0):\n",
    "    for n1, t in enumerate(['N', 'D', 'S'], 0):\n",
    "        p = ax[n][n1]\n",
    "        p.plot(history.history[t + '_' + v][0:])\n",
    "        p.plot(history.history['val_' + t + '_' +  v][0:])\n",
    "        p.legend([t + '_Train', t + '_Test'], loc='center right')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "test, _ = dataset.load_data(dataset.read_corpora(['test/modernTestCorpus/']), 0, MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(units=800)\n",
    "model.load_weights('./checkpoints/modern_over2')\n",
    "x = test.normalized\n",
    "y = {'N': test.niqqud, 'D': test.dagesh, 'S': test.sin }\n",
    "\n",
    "model.compile(loss=sparse_categorical_crossentropy,\n",
    "              metrics={'N': accuracy, 'D': accuracy, 'S': accuracy})\n",
    "\n",
    "_ = model.evaluate(x=x, y=y, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import hebrew\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['modern'][1].normalized[0])\n",
    "print(data['modern'][1].niqqud[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env WANDB_MODE run\n",
    "config = {\n",
    "        'batch_size': 64,\n",
    "        'units': 500,\n",
    "        'order': [\n",
    "            ('mix',    [(30e-4, 80e-4, 1e-4)], 'mix'),\n",
    "            ('modern', [(50e-4, 50e-4, 1e-5)], 'modern'),\n",
    "            ('modern', [(50e-4, 50e-4, 1e-5),\n",
    "                        # (50e-4, 50e-4, 1e-5),\n",
    "                       ], 'modern_over'),\n",
    "        ],\n",
    "    }\n",
    "run = wandb.init(project=\"dotter\",\n",
    "                 # group=\"maxlen\",\n",
    "                 name=f'maxlen_test',\n",
    "                 tags=['CLR', 'ordered'],\n",
    "                 config=config)\n",
    "\n",
    "with run:\n",
    "    for maxlen, letters, words in [\n",
    "            (75, 0.9511, 0.7778),\n",
    "            (80, 0.9531, 0.7819),\n",
    "            (85, 0.9535, 0.7819),\n",
    "            (90, 0.9526, 0.7841),\n",
    "            (95, 0.9514, 0.7795),\n",
    "    ]:\n",
    "        run.log({'maxlen': maxlen,\n",
    "                 'letters': letters,\n",
    "                 'words': words})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(units=400)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit9bb923b013d04c19b7222e7ae44d4e24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
